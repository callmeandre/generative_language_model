{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from TwitterSearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(keyword, df, popular=True):\n",
    "    ''' Extract tweets for the provided keyword, add\n",
    "      to an existing dataframe.\n",
    "    \n",
    "    :param keyword: a word, or list of words, that are the\n",
    "      search item of interest.\n",
    "    :param df: an existing dataframe to which we will append\n",
    "      the Twitter results\n",
    "    :optional popular: whether to pull only popular tweets or not \n",
    "    '''\n",
    "    \n",
    "    tso = TwitterSearchOrder()\n",
    "    tso.set_keywords(keyword)\n",
    "    tso.set_language('en')\n",
    "    tso.set_include_entities(True)\n",
    "    if popular:\n",
    "        tso.set_result_type('popular')\n",
    "\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'VFMa4V6ZFcOblmGEDWR2QJbwq',\n",
    "        consumer_secret = 'rTj4IAPNGUcpi7mVLHa2kdt58VXxk8qWzrbtjga8bVF3ay2f5m',\n",
    "        access_token = '33344041-SkTqNFM9reyHCWpKLspJ1TZx3Wq73WeLC3Ucsbu9p',\n",
    "        access_token_secret = 'WcG1sjJELfuTSFs0ZKehAFhRiIP8d5lNlGZOfmHUvvcNS'\n",
    "    )\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    sleep_for = 60 # sleep for 60 seconds\n",
    "    last_amount_of_queries = 0 # used to detect when new queries are done\n",
    "    \n",
    "    def my_callback_closure(current_ts_instance):\n",
    "        queries, tweets_seen = current_ts_instance.get_statistics()\n",
    "        if queries > 0 and (queries % 5) == 0: # trigger delay every 5th query\n",
    "            print(\"sleeping for 60 seconds triggered\")\n",
    "            time.sleep(60) # sleep for 60 seconds\n",
    "            print(\"waking up\")\n",
    "\n",
    "    for tweet in ts.search_tweets_iterable(tso, callback=my_callback_closure):\n",
    "        row = [tweet['user']['screen_name'], tweet['favorite_count'], \n",
    "               tweet['retweet_count'], tweet['text'],\n",
    "              \"https://twitter.com/{}/status/{}\".format(tweet['user']['screen_name'], tweet['id'])]\n",
    "        df.loc[len(df)] = row\n",
    "\n",
    "        current_amount_of_queries, tweets_seen = ts.get_statistics()\n",
    "        if not last_amount_of_queries == current_amount_of_queries:\n",
    "            last_amount_of_queries = current_amount_of_queries\n",
    "            time.sleep(sleep_for)\n",
    "        \n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    print(\"for {}, we got {} tweets\".format(keyword, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = pd.read_csv(\"data/popular_words.txt\", header=None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ['create'], we got 94 tweets\n",
      "for ['year'], we got 86 tweets\n",
      "for ['draw'], we got 91 tweets\n",
      "for ['dream'], we got 83 tweets\n",
      "for ['front'], we got 95 tweets\n",
      "for ['populate'], we got 285 tweets\n",
      "for ['soon'], we got 90 tweets\n",
      "for ['mother'], we got 84 tweets\n",
      "for ['short'], we got 98 tweets\n",
      "for ['rain'], we got 96 tweets\n",
      "for ['thousand'], we got 81 tweets\n",
      "for ['while'], we got 78 tweets\n",
      "for ['die'], we got 55 tweets\n",
      "for ['include'], we got 89 tweets\n",
      "for ['level'], we got 95 tweets\n",
      "for ['pattern'], we got 88 tweets\n",
      "for ['meet'], we got 92 tweets\n",
      "for ['since'], we got 84 tweets\n",
      "for ['way'], we got 88 tweets\n",
      "for ['gas'], we got 65 tweets\n",
      "for ['bad'], we got 95 tweets\n",
      "for ['suggest'], we got 98 tweets\n",
      "for ['once'], we got 84 tweets\n",
      "for ['key'], we got 85 tweets\n",
      "for ['did'], we got 92 tweets\n",
      "for ['stream'], we got 87 tweets\n",
      "for ['decimal'], we got 99 tweets\n",
      "for ['perhaps'], we got 298 tweets\n",
      "for ['after'], we got 85 tweets\n",
      "for ['lift'], we got 97 tweets\n",
      "for ['surprise'], we got 77 tweets\n",
      "for ['except'], we got 96 tweets\n",
      "for ['fig'], we got 96 tweets\n",
      "for ['pose'], we got 70 tweets\n",
      "for ['camp'], we got 91 tweets\n",
      "for ['position'], we got 85 tweets\n",
      "for ['sudden'], we got 91 tweets\n",
      "for ['unit'], we got 98 tweets\n",
      "for ['green'], we got 95 tweets\n",
      "for ['invent'], we got 95 tweets\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['screen_name','fav','rt','tweet','tweet_url'])\n",
    "\n",
    "for word in popular_words[0].sample(40):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], df, popular=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name    3931\n",
       "fav            3931\n",
       "rt             3931\n",
       "tweet          3931\n",
       "tweet_url      3931\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/regular_tweets_{}.csv\".format(df.count()[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and combine tweets, then drop duplicates\n",
    "df_1 = pd.read_csv(\"data/regular_tweets_1858.csv\")\n",
    "df_2 = pd.read_csv(\"data/regular_tweets_3741.csv\")\n",
    "df_3 = pd.read_csv(\"data/regular_tweets_3931.csv\")\n",
    "df_4 = pd.read_csv(\"data/regular_tweets_3935.csv\")\n",
    "df_5 = pd.read_csv(\"data/regular_tweets_4076.csv\")\n",
    "\n",
    "regular_tweets_df = pd.concat([df_1, df_2, df_3, df_4, df_5]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name    1394\n",
       "fav            1394\n",
       "rt             1394\n",
       "tweet          1394\n",
       "tweet_url      1394\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_tweets_df = pd.read_csv('data/popular_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_tweets_df.to_csv('data/regular_tweets_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
