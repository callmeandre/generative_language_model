{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from TwitterSearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(keyword, df, popular=True):\n",
    "    ''' Extract tweets for the provided keyword, add\n",
    "      to an existing dataframe.\n",
    "    \n",
    "    :param keyword: a word, or list of words, that are the\n",
    "      search item of interest.\n",
    "    :param df: an existing dataframe to which we will append\n",
    "      the Twitter results\n",
    "    :optional popular: whether to pull only popular tweets or not \n",
    "    '''\n",
    "    \n",
    "    tso = TwitterSearchOrder()\n",
    "    tso.set_keywords(keyword)\n",
    "    tso.set_language('en')\n",
    "    tso.set_include_entities(True)\n",
    "    if popular:\n",
    "        tso.set_result_type('popular')\n",
    "\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'VFMa4V6ZFcOblmGEDWR2QJbwq',\n",
    "        consumer_secret = 'rTj4IAPNGUcpi7mVLHa2kdt58VXxk8qWzrbtjga8bVF3ay2f5m',\n",
    "        access_token = '33344041-SkTqNFM9reyHCWpKLspJ1TZx3Wq73WeLC3Ucsbu9p',\n",
    "        access_token_secret = 'WcG1sjJELfuTSFs0ZKehAFhRiIP8d5lNlGZOfmHUvvcNS'\n",
    "    )\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    sleep_for = 60 # sleep for 60 seconds\n",
    "    last_amount_of_queries = 0 # used to detect when new queries are done\n",
    "    \n",
    "    def my_callback_closure(current_ts_instance):\n",
    "        queries, tweets_seen = current_ts_instance.get_statistics()\n",
    "        if queries > 0 and (queries % 5) == 0: # trigger delay every 5th query\n",
    "            print(\"sleeping for 60 seconds triggered\")\n",
    "            time.sleep(60) # sleep for 60 seconds\n",
    "            print(\"waking up\")\n",
    "\n",
    "    for tweet in ts.search_tweets_iterable(tso, callback=my_callback_closure):\n",
    "        row = [tweet['user']['screen_name'], tweet['favorite_count'], \n",
    "               tweet['retweet_count'], tweet['text'],\n",
    "              \"https://twitter.com/{}/status/{}\".format(tweet['user']['screen_name'], tweet['id'])]\n",
    "        df.loc[len(df)] = row\n",
    "\n",
    "        current_amount_of_queries, tweets_seen = ts.get_statistics()\n",
    "        if not last_amount_of_queries == current_amount_of_queries:\n",
    "            last_amount_of_queries = current_amount_of_queries\n",
    "            time.sleep(sleep_for)\n",
    "        \n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    print(\"for {}, we got {} tweets\".format(keyword, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = pd.read_csv(\"data/popular_words.txt\", header=None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ['degree'], we got 84 tweets\n",
      "for ['which'], we got 95 tweets\n",
      "for ['if'], we got 82 tweets\n",
      "for ['lot'], we got 82 tweets\n",
      "for ['allow'], we got 82 tweets\n",
      "for ['station'], we got 86 tweets\n",
      "for ['log'], we got 99 tweets\n",
      "for ['more'], we got 83 tweets\n",
      "for ['cool'], we got 88 tweets\n",
      "for ['sea'], we got 91 tweets\n",
      "for ['number'], we got 95 tweets\n",
      "for ['laugh'], we got 82 tweets\n",
      "for ['band'], we got 90 tweets\n",
      "for ['children'], we got 92 tweets\n",
      "for ['particular'], we got 294 tweets\n",
      "for ['hope'], we got 86 tweets\n",
      "for ['could'], we got 96 tweets\n",
      "for ['contain'], we got 188 tweets\n",
      "for ['discuss'], we got 94 tweets\n",
      "for ['steel'], we got 85 tweets\n",
      "for ['animal'], we got 85 tweets\n",
      "for ['will'], we got 86 tweets\n",
      "for ['ran'], we got 89 tweets\n",
      "for ['ship'], we got 95 tweets\n",
      "for ['take'], we got 99 tweets\n",
      "for ['follow'], we got 87 tweets\n",
      "for ['say'], we got 95 tweets\n",
      "for ['wrote'], we got 93 tweets\n",
      "for ['bought'], we got 93 tweets\n",
      "for ['two'], we got 89 tweets\n",
      "for ['shape'], we got 97 tweets\n",
      "for ['charge'], we got 81 tweets\n",
      "for ['property'], we got 96 tweets\n",
      "for ['element'], we got 91 tweets\n",
      "for ['chance'], we got 93 tweets\n",
      "for ['basic'], we got 94 tweets\n",
      "for ['together'], we got 89 tweets\n",
      "for ['show'], we got 89 tweets\n",
      "for ['fall'], we got 90 tweets\n",
      "for ['room'], we got 85 tweets\n",
      "for ['support'], we got 91 tweets\n",
      "for ['those'], we got 93 tweets\n",
      "sleeping for 60 seconds triggered\n",
      "waking up\n",
      "for ['develop'], we got 498 tweets\n",
      "for ['separate'], we got 197 tweets\n",
      "for ['six'], we got 96 tweets\n",
      "for ['metal'], we got 96 tweets\n",
      "for ['other'], we got 82 tweets\n",
      "for ['watch'], we got 91 tweets\n",
      "for ['grew'], we got 89 tweets\n",
      "for ['brown'], we got 90 tweets\n",
      "for ['black'], we got 84 tweets\n",
      "for ['know'], we got 90 tweets\n"
     ]
    }
   ],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','tweet_url'])\n",
    "\n",
    "for word in popular_words[0].sample(100):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    \n",
    "dfr.to_csv(\"data/new_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name    3976\n",
       "fav            3976\n",
       "rt             3976\n",
       "tweet          3976\n",
       "tweet_url      3976\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.to_csv(\"data/on_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and combine tweets, then drop duplicates\n",
    "#df_1 = pd.read_csv(\"data/regular_tweets_1858.csv\")\n",
    "#df_2 = pd.read_csv(\"data/regular_tweets_3741.csv\")\n",
    "#df_3 = pd.read_csv(\"data/regular_tweets_3931.csv\")\n",
    "#df_4 = pd.read_csv(\"data/regular_tweets_3935.csv\")\n",
    "#df_5 = pd.read_csv(\"data/regular_tweets_4076.csv\")\n",
    "\n",
    "#regular_tweets_df = pd.concat([df_1, df_2, df_3, df_4, df_5]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popular_tweets_df = pd.read_csv('data/popular_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular_tweets_df.to_csv('data/regular_tweets_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ['out'], we got 13 tweets\n",
      "for ['form'], we got 14 tweets\n",
      "for ['track'], we got 14 tweets\n",
      "for ['check'], we got 15 tweets\n",
      "for ['leave'], we got 15 tweets\n",
      "for ['tone'], we got 14 tweets\n",
      "for ['present'], we got 14 tweets\n",
      "for ['poor'], we got 14 tweets\n",
      "for ['length'], we got 15 tweets\n",
      "for ['let'], we got 15 tweets\n",
      "for ['strange'], we got 15 tweets\n",
      "for ['thin'], we got 15 tweets\n",
      "for ['voice'], we got 15 tweets\n",
      "for ['cell'], we got 15 tweets\n",
      "for ['could'], we got 15 tweets\n",
      "for ['by'], we got 14 tweets\n",
      "for ['such'], we got 14 tweets\n",
      "for ['mix'], we got 15 tweets\n",
      "for ['see'], we got 14 tweets\n",
      "for ['correct'], we got 15 tweets\n",
      "for ['second'], we got 13 tweets\n",
      "for ['lot'], we got 15 tweets\n",
      "for ['will'], we got 13 tweets\n",
      "for ['remember'], we got 15 tweets\n",
      "for ['until'], we got 13 tweets\n",
      "for ['since'], we got 15 tweets\n",
      "for ['fast'], we got 14 tweets\n",
      "for ['log'], we got 14 tweets\n",
      "for ['green'], we got 12 tweets\n",
      "for ['red'], we got 14 tweets\n",
      "for ['clean'], we got 15 tweets\n",
      "for ['radio'], we got 15 tweets\n",
      "for ['once'], we got 15 tweets\n",
      "for ['moon'], we got 14 tweets\n",
      "for ['big'], we got 15 tweets\n",
      "for ['moment'], we got 15 tweets\n",
      "for ['and'], we got 14 tweets\n",
      "for ['square'], we got 15 tweets\n",
      "for ['where'], we got 15 tweets\n",
      "for ['fruit'], we got 15 tweets\n",
      "for ['whole'], we got 13 tweets\n",
      "for ['these'], we got 15 tweets\n",
      "for ['whose'], we got 15 tweets\n",
      "for ['natural'], we got 15 tweets\n",
      "for ['feed'], we got 14 tweets\n",
      "for ['gave'], we got 14 tweets\n",
      "for ['sure'], we got 13 tweets\n",
      "for ['throw'], we got 13 tweets\n",
      "for ['imagine'], we got 15 tweets\n",
      "for ['differ'], we got 15 tweets\n",
      "for ['whether'], we got 14 tweets\n",
      "for ['cost'], we got 14 tweets\n",
      "for ['doctor'], we got 14 tweets\n",
      "for ['sell'], we got 13 tweets\n",
      "for ['together'], we got 14 tweets\n",
      "for ['fit'], we got 14 tweets\n",
      "for ['shout'], we got 15 tweets\n",
      "for ['been'], we got 15 tweets\n",
      "for ['win'], we got 14 tweets\n",
      "for ['step'], we got 14 tweets\n",
      "for ['receive'], we got 15 tweets\n",
      "for ['end'], we got 14 tweets\n",
      "for ['valley'], we got 15 tweets\n",
      "for ['beat'], we got 15 tweets\n",
      "for ['have'], we got 11 tweets\n",
      "for ['box'], we got 15 tweets\n",
      "for ['child'], we got 14 tweets\n",
      "for ['home'], we got 15 tweets\n",
      "for ['afraid'], we got 13 tweets\n",
      "for ['yet'], we got 14 tweets\n",
      "for ['man'], we got 14 tweets\n",
      "for ['behind'], we got 15 tweets\n",
      "for ['black'], we got 14 tweets\n",
      "for ['happen'], we got 15 tweets\n",
      "for ['serve'], we got 12 tweets\n",
      "for ['good'], we got 15 tweets\n",
      "for ['cloud'], we got 12 tweets\n",
      "for ['bright'], we got 15 tweets\n",
      "for ['said'], we got 15 tweets\n",
      "for ['this'], we got 14 tweets\n",
      "for ['especially'], we got 14 tweets\n",
      "for ['were'], we got 14 tweets\n",
      "for ['her'], we got 15 tweets\n",
      "for ['energy'], we got 14 tweets\n",
      "for ['did'], we got 14 tweets\n",
      "for ['letter'], we got 14 tweets\n",
      "for ['complete'], we got 15 tweets\n",
      "for ['contain'], we got 13 tweets\n",
      "for ['raise'], we got 12 tweets\n",
      "for ['week'], we got 14 tweets\n",
      "for ['populate'], we got 1 tweets\n",
      "for ['include'], we got 13 tweets\n",
      "for ['just'], we got 15 tweets\n",
      "for ['go'], we got 14 tweets\n",
      "for ['know'], we got 15 tweets\n",
      "for ['touch'], we got 10 tweets\n",
      "for ['stay'], we got 14 tweets\n",
      "for ['bar'], we got 14 tweets\n",
      "for ['left'], we got 10 tweets\n",
      "for ['farm'], we got 15 tweets\n"
     ]
    }
   ],
   "source": [
    "dfp = pd.DataFrame(columns=['screen_name','fav','rt','tweet','tweet_url'])\n",
    "\n",
    "for word in popular_words[0].sample(100):\n",
    "    get_tweets([word], dfp, popular=True)\n",
    "    \n",
    "dfp.to_csv(\"data/on_popular_tweets_{}.csv\".format(dfp.count()[0]), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
