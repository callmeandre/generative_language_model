{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from TwitterSearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(keyword, df, popular=True):\n",
    "    ''' Extract tweets for the provided keyword, add\n",
    "      to an existing dataframe.\n",
    "    \n",
    "    :param keyword: a word, or list of words, that are the\n",
    "      search item of interest.\n",
    "    :param df: an existing dataframe to which we will append\n",
    "      the Twitter results\n",
    "    :optional popular: whether to pull only popular tweets or not \n",
    "    '''\n",
    "    \n",
    "    tso = TwitterSearchOrder()\n",
    "    tso.set_keywords(keyword)\n",
    "    tso.set_language('en')\n",
    "    tso.set_include_entities(True)\n",
    "    if popular:\n",
    "        tso.set_result_type('popular')\n",
    "\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'VFMa4V6ZFcOblmGEDWR2QJbwq',\n",
    "        consumer_secret = 'rTj4IAPNGUcpi7mVLHa2kdt58VXxk8qWzrbtjga8bVF3ay2f5m',\n",
    "        access_token = '33344041-SkTqNFM9reyHCWpKLspJ1TZx3Wq73WeLC3Ucsbu9p',\n",
    "        access_token_secret = 'WcG1sjJELfuTSFs0ZKehAFhRiIP8d5lNlGZOfmHUvvcNS'\n",
    "    )\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    sleep_for = 60 # sleep for 60 seconds\n",
    "    last_amount_of_queries = 0 # used to detect when new queries are done\n",
    "    \n",
    "    def my_callback_closure(current_ts_instance):\n",
    "        queries, tweets_seen = current_ts_instance.get_statistics()\n",
    "        if queries > 0 and (queries % 5) == 0: # trigger delay every 5th query\n",
    "            print(\"sleeping for 60 seconds triggered\")\n",
    "            time.sleep(60) # sleep for 60 seconds\n",
    "            print(\"waking up\")\n",
    "\n",
    "    for tweet in ts.search_tweets_iterable(tso, callback=my_callback_closure):\n",
    "        row = [tweet['user']['screen_name'], tweet['favorite_count'], \n",
    "               tweet['retweet_count'], tweet['text'],\n",
    "              \"https://twitter.com/{}/status/{}\".format(tweet['user']['screen_name'], tweet['id'])]\n",
    "        df.loc[len(df)] = row\n",
    "\n",
    "        current_amount_of_queries, tweets_seen = ts.get_statistics()\n",
    "        if not last_amount_of_queries == current_amount_of_queries:\n",
    "            last_amount_of_queries = current_amount_of_queries\n",
    "            time.sleep(sleep_for)\n",
    "        \n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    print(\"for {}, we got {} tweets\".format(keyword, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = pd.read_csv(\"data/popular_words.txt\", header=None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ['better'], we got 15 tweets\n",
      "for ['me'], we got 14 tweets\n",
      "for ['heart'], we got 15 tweets\n",
      "for ['open'], we got 14 tweets\n",
      "for ['spell'], we got 14 tweets\n",
      "for ['stone'], we got 15 tweets\n",
      "for ['repeat'], we got 13 tweets\n",
      "for ['life'], we got 14 tweets\n",
      "for ['here'], we got 15 tweets\n",
      "for ['many'], we got 14 tweets\n",
      "for ['this'], we got 13 tweets\n",
      "for ['watch'], we got 13 tweets\n",
      "for ['come'], we got 14 tweets\n",
      "for ['lay'], we got 14 tweets\n",
      "for ['depend'], we got 15 tweets\n",
      "for ['supply'], we got 13 tweets\n",
      "for ['felt'], we got 15 tweets\n",
      "for ['human'], we got 14 tweets\n",
      "for ['instrument'], we got 15 tweets\n",
      "for ['quiet'], we got 12 tweets\n",
      "for ['sand'], we got 12 tweets\n",
      "for ['charge'], we got 14 tweets\n",
      "for ['river'], we got 14 tweets\n",
      "for ['protect'], we got 14 tweets\n",
      "for ['summer'], we got 9 tweets\n",
      "for ['difficult'], we got 14 tweets\n",
      "for ['tone'], we got 14 tweets\n",
      "for ['king'], we got 15 tweets\n",
      "for ['busy'], we got 15 tweets\n",
      "for ['front'], we got 15 tweets\n",
      "for ['thus'], we got 13 tweets\n",
      "for ['root'], we got 15 tweets\n",
      "for ['electric'], we got 13 tweets\n",
      "for ['live'], we got 15 tweets\n",
      "for ['meet'], we got 15 tweets\n",
      "for ['as'], we got 13 tweets\n",
      "for ['contain'], we got 15 tweets\n",
      "for ['score'], we got 11 tweets\n",
      "for ['game'], we got 15 tweets\n",
      "for ['read'], we got 14 tweets\n",
      "for ['with'], we got 15 tweets\n",
      "for ['brought'], we got 13 tweets\n",
      "for ['opposite'], we got 14 tweets\n",
      "for ['found'], we got 14 tweets\n",
      "for ['neighbor'], we got 12 tweets\n",
      "for ['product'], we got 13 tweets\n",
      "for ['compare'], we got 15 tweets\n",
      "for ['prove'], we got 15 tweets\n",
      "for ['drop'], we got 13 tweets\n",
      "for ['raise'], we got 14 tweets\n",
      "for ['eye'], we got 13 tweets\n",
      "for ['dark'], we got 14 tweets\n",
      "for ['say'], we got 15 tweets\n",
      "for ['enemy'], we got 14 tweets\n",
      "for ['silent'], we got 14 tweets\n",
      "for ['hole'], we got 12 tweets\n",
      "for ['an'], we got 14 tweets\n",
      "for ['train'], we got 13 tweets\n",
      "for ['why'], we got 14 tweets\n",
      "for ['wear'], we got 13 tweets\n",
      "for ['mind'], we got 12 tweets\n",
      "for ['allow'], we got 14 tweets\n",
      "for ['ride'], we got 14 tweets\n",
      "for ['on'], we got 13 tweets\n",
      "for ['her'], we got 15 tweets\n",
      "for ['observe'], we got 13 tweets\n",
      "for ['natural'], we got 14 tweets\n",
      "for ['hand'], we got 12 tweets\n",
      "for ['mix'], we got 14 tweets\n",
      "for ['boat'], we got 14 tweets\n",
      "for ['act'], we got 15 tweets\n",
      "for ['quick'], we got 14 tweets\n",
      "for ['between'], we got 13 tweets\n",
      "for ['level'], we got 15 tweets\n",
      "for ['morning'], we got 15 tweets\n",
      "for ['soon'], we got 13 tweets\n",
      "for ['space'], we got 15 tweets\n",
      "for ['desert'], we got 14 tweets\n",
      "for ['let'], we got 14 tweets\n",
      "for ['then'], we got 14 tweets\n",
      "for ['lift'], we got 13 tweets\n",
      "for ['travel'], we got 13 tweets\n",
      "for ['pass'], we got 14 tweets\n",
      "for ['wrote'], we got 13 tweets\n",
      "for ['cause'], we got 14 tweets\n",
      "for ['stood'], we got 11 tweets\n",
      "for ['always'], we got 15 tweets\n",
      "for ['even'], we got 14 tweets\n",
      "for ['division'], we got 14 tweets\n",
      "for ['fraction'], we got 15 tweets\n",
      "for ['beat'], we got 15 tweets\n",
      "for ['sell'], we got 14 tweets\n",
      "for ['caught'], we got 14 tweets\n",
      "for ['gun'], we got 15 tweets\n",
      "for ['and'], we got 15 tweets\n",
      "for ['ocean'], we got 15 tweets\n",
      "for ['change'], we got 14 tweets\n",
      "for ['eight'], we got 14 tweets\n",
      "for ['colony'], we got 13 tweets\n",
      "for ['can'], we got 13 tweets\n"
     ]
    }
   ],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','tweet_url'])\n",
    "\n",
    "for word in popular_words[0].sample(100):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=True)\n",
    "    \n",
    "dfr.to_csv(\"data/new2_popular_tweets_{}.csv\".format(dfr.count()[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name    1385\n",
       "fav            1385\n",
       "rt             1385\n",
       "tweet          1385\n",
       "tweet_url      1385\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.to_csv(\"data/on_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and combine tweets, then drop duplicates\n",
    "#df_1 = pd.read_csv(\"data/regular_tweets_1858.csv\")\n",
    "#df_2 = pd.read_csv(\"data/regular_tweets_3741.csv\")\n",
    "#df_3 = pd.read_csv(\"data/regular_tweets_3931.csv\")\n",
    "#df_4 = pd.read_csv(\"data/regular_tweets_3935.csv\")\n",
    "#df_5 = pd.read_csv(\"data/regular_tweets_4076.csv\")\n",
    "\n",
    "#regular_tweets_df = pd.concat([df_1, df_2, df_3, df_4, df_5]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popular_tweets_df = pd.read_csv('data/popular_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular_tweets_df.to_csv('data/regular_tweets_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.DataFrame(columns=['screen_name','fav','rt','tweet','tweet_url'])\n",
    "\n",
    "for word in popular_words[0].sample(100):\n",
    "    get_tweets([word], dfp, popular=True)\n",
    "    \n",
    "dfp.to_csv(\"data/on_popular_tweets_{}.csv\".format(dfp.count()[0]), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
