{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from TwitterSearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(keyword, df, popular=True):\n",
    "    ''' Extract tweets for the provided keyword, add\n",
    "      to an existing dataframe.\n",
    "    \n",
    "    :param keyword: a word, or list of words, that are the\n",
    "      search item of interest.\n",
    "    :param df: an existing dataframe to which we will append\n",
    "      the Twitter results\n",
    "    :optional popular: whether to pull only popular tweets or not \n",
    "    '''\n",
    "    \n",
    "    tso = TwitterSearchOrder()\n",
    "    tso.set_keywords(keyword)\n",
    "    tso.set_language('en')\n",
    "    tso.set_include_entities(True)\n",
    "    if popular:\n",
    "        tso.set_result_type('popular')\n",
    "\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'VFMa4V6ZFcOblmGEDWR2QJbwq',\n",
    "        consumer_secret = 'rTj4IAPNGUcpi7mVLHa2kdt58VXxk8qWzrbtjga8bVF3ay2f5m',\n",
    "        access_token = '33344041-SkTqNFM9reyHCWpKLspJ1TZx3Wq73WeLC3Ucsbu9p',\n",
    "        access_token_secret = 'WcG1sjJELfuTSFs0ZKehAFhRiIP8d5lNlGZOfmHUvvcNS'\n",
    "    )\n",
    "\n",
    "    sleep_for = 60 # sleep for 60 seconds\n",
    "    last_amount_of_queries = 0 # used to detect when new queries are done\n",
    "    \n",
    "    def my_callback_closure(current_ts_instance):\n",
    "        queries, tweets_seen = current_ts_instance.get_statistics()\n",
    "        if queries > 0 and (queries % 5) == 0: # trigger delay every 5th query\n",
    "            print(\"sleeping for 60 seconds triggered\")\n",
    "            time.sleep(60) # sleep for 60 seconds\n",
    "            print(\"waking up\")\n",
    "\n",
    "    for tweet in ts.search_tweets_iterable(tso, callback=my_callback_closure):\n",
    "        row = [tweet['user']['screen_name'], tweet['favorite_count'], \n",
    "               tweet['retweet_count'], tweet['text'], tweet['truncated'],\n",
    "              \"https://twitter.com/{}/status/{}\".format(tweet['user']['screen_name'], tweet['id'])]\n",
    "        df.loc[len(df)] = row\n",
    "\n",
    "        current_amount_of_queries, tweets_seen = ts.get_statistics()\n",
    "        if not last_amount_of_queries == current_amount_of_queries:\n",
    "            last_amount_of_queries = current_amount_of_queries\n",
    "            time.sleep(sleep_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = pd.read_csv(\"data/popular_words.txt\", header=None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "#j = 0\n",
    "#for word in popular_words[0]:\n",
    "#    # concatenate dataframes\n",
    "#    get_tweets([word], dfr, popular=True)\n",
    "#    j += 1\n",
    "#    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "#dfr.to_csv(\"data/with_trunc_popular_tweets_{}.csv\".format(dfr.count()[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just finished word #1\n",
      "just finished word #2\n",
      "just finished word #3\n",
      "just finished word #4\n",
      "just finished word #5\n",
      "just finished word #6\n",
      "just finished word #7\n",
      "just finished word #8\n",
      "just finished word #9\n",
      "just finished word #10\n",
      "just finished word #11\n",
      "just finished word #12\n",
      "just finished word #13\n",
      "just finished word #14\n",
      "just finished word #15\n",
      "sleeping for 60 seconds triggered\n",
      "waking up\n",
      "just finished word #16\n",
      "just finished word #17\n",
      "just finished word #18\n",
      "just finished word #19\n",
      "just finished word #20\n",
      "just finished word #21\n",
      "just finished word #22\n",
      "just finished word #23\n",
      "just finished word #24\n",
      "just finished word #25\n",
      "just finished word #26\n",
      "just finished word #27\n",
      "just finished word #28\n",
      "just finished word #29\n",
      "just finished word #30\n",
      "sleeping for 60 seconds triggered\n",
      "waking up\n",
      "sleeping for 60 seconds triggered\n",
      "waking up\n",
      "just finished word #31\n",
      "just finished word #32\n",
      "just finished word #33\n",
      "just finished word #34\n",
      "just finished word #35\n",
      "just finished word #36\n",
      "just finished word #37\n",
      "just finished word #38\n",
      "just finished word #39\n",
      "just finished word #40\n",
      "just finished word #41\n",
      "just finished word #42\n",
      "just finished word #43\n",
      "just finished word #44\n",
      "just finished word #45\n",
      "just finished word #46\n",
      "just finished word #47\n",
      "just finished word #48\n",
      "just finished word #49\n",
      "just finished word #50\n",
      "just finished word #51\n",
      "just finished word #52\n",
      "just finished word #53\n",
      "just finished word #54\n",
      "just finished word #55\n",
      "just finished word #56\n",
      "just finished word #57\n",
      "just finished word #58\n",
      "just finished word #59\n",
      "just finished word #60\n",
      "just finished word #61\n",
      "just finished word #62\n",
      "just finished word #63\n",
      "just finished word #64\n",
      "just finished word #65\n",
      "just finished word #66\n",
      "just finished word #67\n",
      "just finished word #68\n",
      "just finished word #69\n",
      "just finished word #70\n",
      "just finished word #71\n",
      "just finished word #72\n",
      "just finished word #73\n",
      "just finished word #74\n",
      "just finished word #75\n",
      "just finished word #76\n",
      "just finished word #77\n",
      "just finished word #78\n",
      "just finished word #79\n",
      "just finished word #80\n",
      "just finished word #81\n",
      "just finished word #82\n",
      "just finished word #83\n",
      "just finished word #84\n",
      "just finished word #85\n",
      "just finished word #86\n",
      "just finished word #87\n",
      "just finished word #88\n",
      "just finished word #89\n",
      "just finished word #90\n",
      "just finished word #91\n",
      "just finished word #92\n",
      "just finished word #93\n",
      "just finished word #94\n",
      "just finished word #95\n",
      "just finished word #96\n",
      "just finished word #97\n",
      "just finished word #98\n",
      "just finished word #99\n",
      "just finished word #100\n",
      "just finished word #101\n",
      "just finished word #102\n",
      "just finished word #103\n",
      "just finished word #104\n",
      "just finished word #105\n",
      "just finished word #106\n",
      "just finished word #107\n",
      "just finished word #108\n",
      "just finished word #109\n",
      "just finished word #110\n",
      "just finished word #111\n",
      "just finished word #112\n",
      "just finished word #113\n",
      "just finished word #114\n",
      "just finished word #115\n",
      "just finished word #116\n",
      "just finished word #117\n",
      "just finished word #118\n",
      "just finished word #119\n",
      "just finished word #120\n",
      "just finished word #121\n",
      "just finished word #122\n",
      "just finished word #123\n",
      "just finished word #124\n",
      "just finished word #125\n",
      "just finished word #126\n",
      "just finished word #127\n",
      "just finished word #128\n",
      "just finished word #129\n",
      "just finished word #130\n",
      "just finished word #131\n",
      "just finished word #132\n",
      "just finished word #133\n",
      "just finished word #134\n",
      "just finished word #135\n",
      "just finished word #136\n",
      "just finished word #137\n",
      "just finished word #138\n",
      "just finished word #139\n",
      "just finished word #140\n",
      "just finished word #141\n",
      "just finished word #142\n",
      "just finished word #143\n",
      "just finished word #144\n",
      "just finished word #145\n",
      "just finished word #146\n",
      "just finished word #147\n",
      "just finished word #148\n",
      "just finished word #149\n",
      "just finished word #150\n",
      "just finished word #151\n",
      "just finished word #152\n",
      "just finished word #153\n",
      "just finished word #154\n",
      "just finished word #155\n",
      "just finished word #156\n",
      "just finished word #157\n",
      "just finished word #158\n",
      "just finished word #159\n",
      "just finished word #160\n",
      "just finished word #161\n",
      "just finished word #162\n",
      "just finished word #163\n",
      "just finished word #164\n",
      "just finished word #165\n",
      "just finished word #166\n",
      "just finished word #167\n",
      "just finished word #168\n",
      "just finished word #169\n",
      "just finished word #170\n",
      "sleeping for 60 seconds triggered\n",
      "waking up\n",
      "just finished word #171\n",
      "just finished word #172\n",
      "just finished word #173\n",
      "sleeping for 60 seconds triggered\n",
      "waking up\n",
      "just finished word #174\n",
      "just finished word #175\n",
      "just finished word #176\n",
      "just finished word #177\n",
      "just finished word #178\n",
      "just finished word #179\n",
      "just finished word #180\n",
      "just finished word #181\n",
      "just finished word #182\n",
      "just finished word #183\n",
      "just finished word #184\n",
      "just finished word #185\n",
      "just finished word #186\n",
      "just finished word #187\n",
      "just finished word #188\n",
      "just finished word #189\n",
      "just finished word #190\n",
      "just finished word #191\n",
      "just finished word #192\n",
      "just finished word #193\n",
      "sleeping for 60 seconds triggered\n",
      "waking up\n",
      "just finished word #194\n",
      "just finished word #195\n",
      "just finished word #196\n",
      "just finished word #197\n",
      "just finished word #198\n",
      "just finished word #199\n",
      "just finished word #200\n",
      "screen_name    26239\n",
      "fav            26239\n",
      "rt             26239\n",
      "tweet          26239\n",
      "truncated      26239\n",
      "tweet_url      26239\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just finished word #1\n",
      "just finished word #2\n",
      "just finished word #3\n",
      "just finished word #4\n",
      "just finished word #5\n",
      "just finished word #6\n",
      "just finished word #7\n",
      "just finished word #8\n",
      "just finished word #9\n",
      "just finished word #10\n",
      "just finished word #11\n",
      "just finished word #12\n",
      "just finished word #13\n",
      "just finished word #14\n",
      "just finished word #15\n"
     ]
    }
   ],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen_name    36593\n",
      "fav            36591\n",
      "rt             36591\n",
      "tweet          36590\n",
      "truncated      36589\n",
      "tweet_url      36589\n",
      "dtype: int64\n",
      "screen_name    29083\n",
      "fav            29083\n",
      "rt             29083\n",
      "tweet          29083\n",
      "truncated      29083\n",
      "tweet_url      29083\n",
      "dtype: int64\n",
      "screen_name    13828\n",
      "fav            13828\n",
      "rt             13828\n",
      "tweet          13828\n",
      "truncated      13828\n",
      "tweet_url      13828\n",
      "dtype: int64\n",
      "screen_name    3156\n",
      "fav            3156\n",
      "rt             3156\n",
      "tweet          3156\n",
      "truncated      3156\n",
      "tweet_url      3156\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>fav</th>\n",
       "      <th>rt</th>\n",
       "      <th>tweet</th>\n",
       "      <th>truncated</th>\n",
       "      <th>tweet_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AsheSchow</td>\n",
       "      <td>21488</td>\n",
       "      <td>8734</td>\n",
       "      <td>Kirsten Gillibrand: “The first thing I would d...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/AsheSchow/status/115674293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JoyceWhiteVance</td>\n",
       "      <td>33889</td>\n",
       "      <td>8031</td>\n",
       "      <td>With all due respect, if you’re a Democrat &amp;am...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/JoyceWhiteVance/status/115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>69933</td>\n",
       "      <td>13646</td>\n",
       "      <td>Very low ratings for the Democratic Debate las...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>halsey</td>\n",
       "      <td>56610</td>\n",
       "      <td>11302</td>\n",
       "      <td>you know,\\nthe good die young,\\nbut so did thi...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/halsey/status/115674508507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RepJoeKennedy</td>\n",
       "      <td>21449</td>\n",
       "      <td>6836</td>\n",
       "      <td>Our President is a gruesome iteration of the s...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/RepJoeKennedy/status/11566...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        screen_name    fav     rt  \\\n",
       "3         AsheSchow  21488   8734   \n",
       "7   JoyceWhiteVance  33889   8031   \n",
       "8   realDonaldTrump  69933  13646   \n",
       "9            halsey  56610  11302   \n",
       "22    RepJoeKennedy  21449   6836   \n",
       "\n",
       "                                                tweet  truncated  \\\n",
       "3   Kirsten Gillibrand: “The first thing I would d...      False   \n",
       "7   With all due respect, if you’re a Democrat &am...      False   \n",
       "8   Very low ratings for the Democratic Debate las...      False   \n",
       "9   you know,\\nthe good die young,\\nbut so did thi...      False   \n",
       "22  Our President is a gruesome iteration of the s...      False   \n",
       "\n",
       "                                            tweet_url  \n",
       "3   https://twitter.com/AsheSchow/status/115674293...  \n",
       "7   https://twitter.com/JoyceWhiteVance/status/115...  \n",
       "8   https://twitter.com/realDonaldTrump/status/115...  \n",
       "9   https://twitter.com/halsey/status/115674508507...  \n",
       "22  https://twitter.com/RepJoeKennedy/status/11566...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import and combine tweets, then drop duplicates\n",
    "df_1 = pd.read_csv(\"data/with_trunc_regular_tweets_36590.csv\")\n",
    "df_1_nt = df_1[df_1['truncated'] == False]\n",
    "df_2 = pd.read_csv(\"data/with_trunc_popular_tweets_13828.csv\")\n",
    "df_2_nt = df_2[df_2['truncated'] == False]\n",
    "\n",
    "\n",
    "\n",
    "print(df_1.count())\n",
    "print(df_1_nt.count())\n",
    "df_1_nt.head()\n",
    "\n",
    "print(df_2.count())\n",
    "print(df_2_nt.count())\n",
    "display(df_2_nt.head())\n",
    "\n",
    "combined_tweets_df = pd.concat([df_1_nt, df_2_nt]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "combined_tweets_df.to_csv('data/combined_tweets_20190802_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popular_tweets_df = pd.read_csv('data/popular_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular_tweets_df.to_csv('data/regular_tweets_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
