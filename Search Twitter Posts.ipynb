{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from TwitterSearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(keyword, df, popular=True):\n",
    "    ''' Extract tweets for the provided keyword, add\n",
    "      to an existing dataframe.\n",
    "    \n",
    "    :param keyword: a word, or list of words, that are the\n",
    "      search item of interest.\n",
    "    :param df: an existing dataframe to which we will append\n",
    "      the Twitter results\n",
    "    :optional popular: whether to pull only popular tweets or not \n",
    "    '''\n",
    "    \n",
    "    tso = TwitterSearchOrder()\n",
    "    tso.set_keywords(keyword)\n",
    "    tso.set_language('en')\n",
    "    tso.set_include_entities(True)\n",
    "    if popular:\n",
    "        tso.set_result_type('popular')\n",
    "\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'VFMa4V6ZFcOblmGEDWR2QJbwq',\n",
    "        consumer_secret = 'rTj4IAPNGUcpi7mVLHa2kdt58VXxk8qWzrbtjga8bVF3ay2f5m',\n",
    "        access_token = '33344041-SkTqNFM9reyHCWpKLspJ1TZx3Wq73WeLC3Ucsbu9p',\n",
    "        access_token_secret = 'WcG1sjJELfuTSFs0ZKehAFhRiIP8d5lNlGZOfmHUvvcNS'\n",
    "    )\n",
    "\n",
    "    sleep_for = 60 # sleep for 60 seconds\n",
    "    last_amount_of_queries = 0 # used to detect when new queries are done\n",
    "    \n",
    "    def my_callback_closure(current_ts_instance):\n",
    "        queries, tweets_seen = current_ts_instance.get_statistics()\n",
    "        if queries > 0 and (queries % 5) == 0: # trigger delay every 5th query\n",
    "            print(\"sleeping for 60 seconds triggered\")\n",
    "            time.sleep(60) # sleep for 60 seconds\n",
    "            print(\"waking up\")\n",
    "\n",
    "    for tweet in ts.search_tweets_iterable(tso, callback=my_callback_closure):\n",
    "        row = [tweet['user']['screen_name'], tweet['favorite_count'], \n",
    "               tweet['retweet_count'], tweet['text'], tweet['truncated'],\n",
    "              \"https://twitter.com/{}/status/{}\".format(tweet['user']['screen_name'], tweet['id'])]\n",
    "        df.loc[len(df)] = row\n",
    "\n",
    "        current_amount_of_queries, tweets_seen = ts.get_statistics()\n",
    "        if not last_amount_of_queries == current_amount_of_queries:\n",
    "            last_amount_of_queries = current_amount_of_queries\n",
    "            time.sleep(sleep_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = pd.read_csv(\"data/popular_words.txt\", header=None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "#j = 0\n",
    "#for word in popular_words[0]:\n",
    "#    # concatenate dataframes\n",
    "#    get_tweets([word], dfr, popular=True)\n",
    "#    j += 1\n",
    "#    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "#dfr.to_csv(\"data/with_trunc_popular_tweets_{}.csv\".format(dfr.count()[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just finished word #1\n"
     ]
    }
   ],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just finished word #1\n",
      "just finished word #2\n",
      "just finished word #3\n",
      "just finished word #4\n",
      "just finished word #5\n",
      "just finished word #6\n",
      "just finished word #7\n",
      "just finished word #8\n",
      "just finished word #9\n",
      "just finished word #10\n",
      "just finished word #11\n",
      "just finished word #12\n",
      "just finished word #13\n",
      "just finished word #14\n",
      "just finished word #15\n"
     ]
    }
   ],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.DataFrame(columns=['screen_name','fav','rt','tweet','truncated','tweet_url'])\n",
    "j = 0\n",
    "for word in popular_words[0].sample(200):\n",
    "    # concatenate dataframes\n",
    "    get_tweets([word], dfr, popular=False)\n",
    "    j += 1\n",
    "    print(\"just finished word #{}\".format(j))\n",
    "    \n",
    "dfr.to_csv(\"data/with_trunc_regular_tweets_{}.csv\".format(dfr.count()[0]), index=False)\n",
    "print(dfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen_name    36593\n",
      "fav            36591\n",
      "rt             36591\n",
      "tweet          36590\n",
      "truncated      36589\n",
      "tweet_url      36589\n",
      "dtype: int64\n",
      "screen_name    29083\n",
      "fav            29083\n",
      "rt             29083\n",
      "tweet          29083\n",
      "truncated      29083\n",
      "tweet_url      29083\n",
      "dtype: int64\n",
      "screen_name    13828\n",
      "fav            13828\n",
      "rt             13828\n",
      "tweet          13828\n",
      "truncated      13828\n",
      "tweet_url      13828\n",
      "dtype: int64\n",
      "screen_name    3156\n",
      "fav            3156\n",
      "rt             3156\n",
      "tweet          3156\n",
      "truncated      3156\n",
      "tweet_url      3156\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>fav</th>\n",
       "      <th>rt</th>\n",
       "      <th>tweet</th>\n",
       "      <th>truncated</th>\n",
       "      <th>tweet_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AsheSchow</td>\n",
       "      <td>21488</td>\n",
       "      <td>8734</td>\n",
       "      <td>Kirsten Gillibrand: “The first thing I would d...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/AsheSchow/status/115674293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JoyceWhiteVance</td>\n",
       "      <td>33889</td>\n",
       "      <td>8031</td>\n",
       "      <td>With all due respect, if you’re a Democrat &amp;am...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/JoyceWhiteVance/status/115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>69933</td>\n",
       "      <td>13646</td>\n",
       "      <td>Very low ratings for the Democratic Debate las...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>halsey</td>\n",
       "      <td>56610</td>\n",
       "      <td>11302</td>\n",
       "      <td>you know,\\nthe good die young,\\nbut so did thi...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/halsey/status/115674508507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RepJoeKennedy</td>\n",
       "      <td>21449</td>\n",
       "      <td>6836</td>\n",
       "      <td>Our President is a gruesome iteration of the s...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/RepJoeKennedy/status/11566...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        screen_name    fav     rt  \\\n",
       "3         AsheSchow  21488   8734   \n",
       "7   JoyceWhiteVance  33889   8031   \n",
       "8   realDonaldTrump  69933  13646   \n",
       "9            halsey  56610  11302   \n",
       "22    RepJoeKennedy  21449   6836   \n",
       "\n",
       "                                                tweet  truncated  \\\n",
       "3   Kirsten Gillibrand: “The first thing I would d...      False   \n",
       "7   With all due respect, if you’re a Democrat &am...      False   \n",
       "8   Very low ratings for the Democratic Debate las...      False   \n",
       "9   you know,\\nthe good die young,\\nbut so did thi...      False   \n",
       "22  Our President is a gruesome iteration of the s...      False   \n",
       "\n",
       "                                            tweet_url  \n",
       "3   https://twitter.com/AsheSchow/status/115674293...  \n",
       "7   https://twitter.com/JoyceWhiteVance/status/115...  \n",
       "8   https://twitter.com/realDonaldTrump/status/115...  \n",
       "9   https://twitter.com/halsey/status/115674508507...  \n",
       "22  https://twitter.com/RepJoeKennedy/status/11566...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import and combine tweets, then drop duplicates\n",
    "df_1 = pd.read_csv(\"data/with_trunc_regular_tweets_36590.csv\")\n",
    "df_1_nt = df_1[df_1['truncated'] == False]\n",
    "df_2 = pd.read_csv(\"data/with_trunc_popular_tweets_13828.csv\")\n",
    "df_2_nt = df_2[df_2['truncated'] == False]\n",
    "\n",
    "\n",
    "\n",
    "print(df_1.count())\n",
    "print(df_1_nt.count())\n",
    "df_1_nt.head()\n",
    "\n",
    "print(df_2.count())\n",
    "print(df_2_nt.count())\n",
    "display(df_2_nt.head())\n",
    "\n",
    "combined_tweets_df = pd.concat([df_1_nt, df_2_nt]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "combined_tweets_df.to_csv('data/combined_tweets_20190802_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popular_tweets_df = pd.read_csv('data/popular_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular_tweets_df.to_csv('data/regular_tweets_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
