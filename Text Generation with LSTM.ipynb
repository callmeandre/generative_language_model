{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os, re\n",
    "import psutil\n",
    "\n",
    "# keras module for building LSTM \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "[My notes]\n",
    "This is just a bunch of strings we are importing. That's what trains our model. And it's sort of a small corpus, too. \n",
    "\n",
    "I could feed it Tweets, or a bunch of Reddit stuff, and then ask the model to generate text based on an input sequence. I could even build models for each subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @DhaSickest I don‚Äôt know if the officer had probable cause for arrest because that would‚Äôve occurred before the vid‚Ä¶ https://t.co/wDzYo3Yn9q    \n",
       "1        @Costello_stats @globalnews Not surprising given the probable demographic you belong to. ü§∑üèª‚Äç‚ôÇÔ∏è                                                  \n",
       "2        \"The quantum cosmological model wants to describe our universe as a reasonably probable outcome of a quantum mechan‚Ä¶ https://t.co/kyTm0YACS1    \n",
       "3        #Lessors can apply a general reserve to operating lease receivables that are probable of collection. Learn about yo‚Ä¶ https://t.co/Akxj1fb8eH    \n",
       "4        @FleischmanSteve @LuvnlightCreek @buddylady52 @EdLaborCmte So the median family, in addition to 4% wage growth sinc‚Ä¶ https://t.co/1A4BEOhrYB    \n",
       "5        1/2\\nThere were times in our history when the resolution of #KashmirIssue seemed probable, but every time the boat o‚Ä¶ https://t.co/fShoDNgtcd   \n",
       "6        Reason: \\nA group persecution of #Yazidis in the Sinjar Mountains was no longer \"sufficiently probable\", after the t‚Ä¶ https://t.co/ejeibmkbQS   \n",
       "7        @cjciaramella a positive drug field test does NOT establish probable cause                                                                      \n",
       "8        Scrolling through so much news of conferences I can't attend or submit proposals for, and trying hard not to think‚Ä¶ https://t.co/qzOzoyxbTI     \n",
       "9        @wilkyplays @LeodJustin @raoulfgonzo @DemocraticPuni1 Detainment w/o probable cause (visibly seeing or smelling a c‚Ä¶ https://t.co/ZfO0Aev7H2    \n",
       "10       It's probable it's Zac Gambill's together with Scandinavian the and great news for Science it's Zac Gambill's Choct‚Ä¶ https://t.co/QVStYDZ28D    \n",
       "11       @QuancyClayborne It is probability, Isn‚Äôt it? If, based on a long and documented history, it is 99% probable the pe‚Ä¶ https://t.co/24IRMX3D1g    \n",
       "12       @NateSilver538 But trump shouldn‚Äôt be embarrassed for refusing to release them, hiding possible if not probable crimes in the process?          \n",
       "13       55 'probable' Legionnaires' cases tied to Atlanta hotel - WDBJ7 - https://t.co/FJAC0ku9vR https://t.co/Vt3jVhhOXt                               \n",
       "14       @Meitnerium4 @NoeChiron @TrueKingOfSkill The strategy is possible, but not probable.                                                            \n",
       "15       @teechalamet hmmm... possible but not probable                                                                                                  \n",
       "16       The comedienne, @WhitneyCummings, should probably be flagged as a probable manifesto-writer. What she has said to s‚Ä¶ https://t.co/YdGHogt7oO    \n",
       "17       @chupe_y @Jasyfancy @vanguardngrnews @MBuhari @BuhariCentre @OfficialAPCNg @OfficialPDPNig @ApgaHQ @Laurestar‚Ä¶ https://t.co/pLsJMaxvsP          \n",
       "18       Georgia officials say it is probable that dozens of people have contracted the disease. No deaths have been reporte‚Ä¶ https://t.co/OJqyo8x3XY    \n",
       "19       @MGLaValva @TBrownYahoo @SFGiants Its possible that you are smarter than Zaidi. Not remotely probable though.                                   \n",
       "20       Tampa Bay - CF Tommy Pham (hand) has been upgraded to probable tonight versus Boston.                                                           \n",
       "21       You aren't going to tell us the name of the hotel because it\" \"Prominent\"\\n\\nhttps://t.co/kvCYWNUM0B                                            \n",
       "22       55 ‚Äòprobable‚Äô Legionnaires‚Äô cases linked to Sheraton Atlanta; 11 confirmed - Atlanta Journal Constitution‚Ä¶ https://t.co/cTUJJzNhjl              \n",
       "23       @DeeDeeRex @wilkyplays @raoulfgonzo @DemocraticPuni1 Felony speeding provides probable cause. Pick up a law book                                \n",
       "24       @pmobbs Can‚Äôt see it being anything other than a hung parliament Boris will also ship votes to the Lib Dem‚Äôs - most‚Ä¶ https://t.co/NJ0M547xAN    \n",
       "25       The  next probable refugee influx into #Bangladesh is from #India which is mulling to deport 4 million what they sa‚Ä¶ https://t.co/TZ0OksGCVw    \n",
       "26       What I want to happen, mixed with what is still probable:\\n\\nHungary - Verstappen\\nBelgium - Leclerc \\nItaly - Vettel‚Ä¶ https://t.co/98yNez2uHf  \n",
       "27       and the scholarship is just appalling, he often just conveniently takes something from a single author to impute it‚Ä¶ https://t.co/UuDZ3hS15z    \n",
       "28       IF YOU WANT REAL COMIC RELIEF, ASK PETER SUTHERLAND AND JOEL WRIGHT ABOUT THE \"WORLD FAMOUS BUTT PLUGS\" I USED TO P‚Ä¶ https://t.co/kVfeuZjpeK    \n",
       "29       @clarencenyc Have yall see this (*sue em*)üìöüìöüìö\\nhttps://t.co/VJynLsH3b8                                                                          \n",
       "                                          ...                                                                                                            \n",
       "22823    An ASAP Rocky fan was arrested after threatening to blow up the Swedish Embassy ‚¨áÔ∏è\\nhttps://t.co/ni6X3gAKZ6                                     \n",
       "22824    Quick prediction, Jake Paul won‚Äôt actually run any races because it will blow his trim back and reveal the hairline from hell                   \n",
       "22825    Happy Sunday from the one &amp; only Sojourner Truth Pressley Harris aka SoJo! What can I say, a girl knows her angles‚Ä¶ https://t.co/JUl2wnh1gz \n",
       "22826    This weekend some players will be walking away with hundreds of thousands of dollars and some with millions.\\n\\nMy on‚Ä¶ https://t.co/lpfhTQAqCA  \n",
       "22827    There are only three PMI's in the world that are above 50 - India, Brazil and the US. All three are decelerating to‚Ä¶ https://t.co/uN3IPgf0GJ    \n",
       "22828    Chris Brown joins Davido on their Afrobeats collaboration ‚ÄúBlow My Mind.‚Äù Listen: https://t.co/pV82GHmU2N https://t.co/orK0l9y8Tw               \n",
       "22829    This has been looming for several weeks and could be another blow to the Giants WR group https://t.co/QP6MlsHQ81                                \n",
       "22830    WATCH: @reginevalcasid  and Toni's duet will blow you away!  #ASAPNatinTo @ASAPOFFICIAL https://t.co/OnvQS1nxgo                                 \n",
       "22831    The banned terror group Indian Mujahideen (IM) has threatened to blow up the Bareilly railway station in Uttar Prad‚Ä¶ https://t.co/JuDbXFMOI3    \n",
       "22832    nah we go do wona own wey it go blow pass ein own. ü§ûüèæ https://t.co/mGvRkPLfnd                                                                   \n",
       "22833    A 26-year-old woman was arrested after she allegedly threatened to \"blow up\" the Swedish Embassy in support of ASAP‚Ä¶ https://t.co/QgEk0LtUjR    \n",
       "22834    A$AP Rocky fan arrested after threatening to blow up Swedish embassy https://t.co/CA7Ua9Lqzb https://t.co/jn1eyLkesh                            \n",
       "22835    The majestic natural beauty of Banff will blow you away. https://t.co/Jg89mPSZQp                                                                \n",
       "22836    How are you choosing to spend your Sunday in #FireEmblem: Three Houses? From building relationships with other char‚Ä¶ https://t.co/OegG3jqlX8    \n",
       "22837    .@HouseDemocrats had a busy first #200DaysOfProgress:\\n-Strengthening pre-existing condition protections \\n-Taking ac‚Ä¶ https://t.co/Cfr0GvMMax  \n",
       "22838    August is a Big Month for Tamil Cinema\\n#NerKondaPaarvai #Kappaan #Saaho\\nBack to Back busy week for theatres !!\\nPret‚Ä¶ https://t.co/X6z5cfZG2Z \n",
       "22839    Be so busy improving yourself that you don‚Äôt have time to pay attention to anyone/ thing that deters you from  growing.                         \n",
       "22840    Recall that Mitt Romney wrote an op-ed promising he would stand up to Trump's racism. Guess he's busy today. \\n\\nSinc‚Ä¶ https://t.co/0qBEW12dIN  \n",
       "22841    The president needs to fix a city? Was Obama too busy? Are all elected officials from the mayor on up to the goveno‚Ä¶ https://t.co/PjvyDESMex    \n",
       "22842    @RashidaTlaib You have no idea what the country demands. You‚Äôre too busy hating it.                                                             \n",
       "22843    This year‚Äôs @airtattoo was very busy for the #redarrows - from flying @astro_timpeake and a flypast with‚Ä¶ https://t.co/JiGV2x4nkR               \n",
       "22844    This concept is mine. Glamour has completely taken my series &amp; marked it as their own. Last year they briefly menti‚Ä¶ https://t.co/oZt4bkh2HZ\n",
       "22845    WATCH: @DonaldJTrumpJr gets emotional at the border wall: \"My own mother was one of the people who escaped communis‚Ä¶ https://t.co/PrMYTQRlc2    \n",
       "22846    even ya own fans be doing it for the clout. damn.                                                                                               \n",
       "22847    So let‚Äôs deconstruct Chuck Todd‚Äôs intv, with @SenRickScott, shall we?\\n\\nFirst, he starts with a yes/no question. Nev‚Ä¶ https://t.co/0fciyvIjJJ  \n",
       "22848    The kids of the future üèà\\n\\nAntonio Brown and Derek Carr's sons had their own training camp üòÑ (via @AB84) https://t.co/GuOBsKMr6a               \n",
       "22849    [MUST WATCH]: CIC @Julius_S_Malema embracing Jub Jub after his performance at the EFF 6th Anniversary Celebration‚Ä¶ https://t.co/6Kh49Od0SJ      \n",
       "22850    This is an absolute lie. I write my own speeches/points &amp; it is so evident from whatever I have spoken that I talk‚Ä¶ https://t.co/fECNwzPd08 \n",
       "22851    The brave conquer the enemy. The coward conquer their own people. Imran govt puts renowned columnist, writer, retd‚Ä¶ https://t.co/oD7xQBKy3E     \n",
       "22852    If Pakistan wants its own moon landing, it needs to chase a culture of science of the kind Nehru built for India...‚Ä¶ https://t.co/2t5EgZmk2e    \n",
       "Name: body, Length: 22853, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "screen_name    22853\n",
       "fav            22853\n",
       "rt             22853\n",
       "body           22853\n",
       "tweet_url      22853\n",
       "is_popular     22853\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('data/all_tweets_clean.csv', engine='python')\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(tweets['body'])\n",
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Cleaning\n",
    "\n",
    "[My notes]: The data is relatively clean as-is, so we don't have to do that much cleaning. If reddit, might need to do more. If Twitter, think it'll be relatively easy since the data is somewhat clean as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dhasickest i dont know if the officer had probable cause for arrest because that wouldve occurred before the vid ',\n",
       " 'costellostats globalnews not surprising given the probable demographic you belong to ',\n",
       " 'the quantum cosmological model wants to describe our universe as a reasonably probable outcome of a quantum mechan ',\n",
       " 'lessors can apply a general reserve to operating lease receivables that are probable of collection learn about yo ',\n",
       " 'fleischmansteve luvnlightcreek buddylady52 edlaborcmte so the median family in addition to 4 wage growth sinc ',\n",
       " '12\\nthere were times in our history when the resolution of kashmirissue seemed probable but every time the boat o ',\n",
       " 'reason \\na group persecution of yazidis in the sinjar mountains was no longer sufficiently probable after the t ',\n",
       " 'cjciaramella a positive drug field test does not establish probable cause',\n",
       " 'scrolling through so much news of conferences i cant attend or submit proposals for and trying hard not to think ',\n",
       " 'wilkyplays leodjustin raoulfgonzo democraticpuni1 detainment wo probable cause visibly seeing or smelling a c ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(txt):\n",
    "    txt = re.sub(r'https:\\/\\/t[.]co\\/[A-Za-z0-9]*$', '', txt)\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "corpus = [clean_text(x) for x in tweets.body]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354429"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]\n",
    "\n",
    "len(inp_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Sequences and Obtaining Variables: Predictors and Targetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    # the predictors will be all tokens except last one,\n",
    "    # which will be the label\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    \n",
    "    # create a sparse matrix with the labels\n",
    "    # label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 31, 10)            492160    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49216)             4970816   \n",
      "=================================================================\n",
      "Total params: 5,507,376\n",
      "Trainable params: 5,507,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0802 03:22:50.504038 139759770244928 deprecation.py:323] From /home/migueljaime/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173408/354429 [=============>................] - ETA: 10:32 - loss: 8.4527"
     ]
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    ''' generate a text snippet based on \n",
    "    \n",
    "    '''\n",
    "    # for every word of the length we want\n",
    "    for _ in range(next_words):\n",
    "        # tokenize the text we already have\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        # seems like we pad it?\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        # predit using our model!\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        # here it seems that we loop through the returned indexes in\n",
    "        # the tokenizer (how is it populated though?)\n",
    "        # and if they match the prediction, we store them as output.\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            # if the index is the same as the predicted word\n",
    "            if index == predicted:\n",
    "                # extract the word and store it as output\n",
    "                output_word = word\n",
    "                break\n",
    "        # then update the seed text with this prediction\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('Click here', 20, model, max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
